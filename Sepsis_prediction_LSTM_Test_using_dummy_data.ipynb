{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EHRs : \n",
      "ResNet10 : \n",
      "  Acc      :  0.6\n",
      "  AUROC    :  0.64\n",
      "  AUPRC    :  0.709\n",
      "  Precision:  0.556\n",
      "  Recall   :  1.0\n",
      "  F1-score :  0.714\n",
      "\n",
      "\n",
      "EHRs_DrugRel : \n",
      "ResNet10 : \n",
      "  Acc      :  0.8\n",
      "  AUROC    :  0.88\n",
      "  AUPRC    :  0.903\n",
      "  Precision:  0.714\n",
      "  Recall   :  1.0\n",
      "  F1-score :  0.833\n",
      "\n",
      "\n",
      "EHRs_DrugRel_Lab : \n",
      "ResNet10 : \n",
      "  Acc      :  0.7\n",
      "  AUROC    :  0.92\n",
      "  AUPRC    :  0.943\n",
      "  Precision:  0.667\n",
      "  Recall   :  0.8\n",
      "  F1-score :  0.727\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from utils.Dataset import Dataset\n",
    "from net.networks import lstm\n",
    "import random\n",
    "import torch.random\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_auc_score,average_precision_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed(123)\n",
    "np.random.seed(123)\n",
    "random.seed(123)\n",
    "\n",
    "EHRs_DrugRel_Lab = pd.read_csv(\"preprocessed_data(dummy)/(dummy)rnn_EHRs_DrugRel_Lab.csv\")\n",
    "Lab_col=EHRs_DrugRel_Lab.columns[101:136]\n",
    "DrugRel_col=EHRs_DrugRel_Lab.columns[346:1741]\n",
    "EHRs_DrugRel=EHRs_DrugRel_Lab.drop(Lab_col.values,axis=1)\n",
    "EHRs=EHRs_DrugRel.drop(DrugRel_col,axis=1)\n",
    "\n",
    "data={\"EHRs\":EHRs,\"EHRs_DrugRel\":EHRs_DrugRel,\"EHRs_DrugRel_Lab\":EHRs_DrugRel_Lab}\n",
    "\n",
    "for d in data.keys():\n",
    "    data_df=data[d]\n",
    "    print(d,\": \")\n",
    "    \n",
    "    label_df = data_df.drop_duplicates([\"PT_ID\",\"Sepsis_Date\"],keep=\"last\")\n",
    "    padding = pd.DataFrame(0*np.ones((len(data_df), 1742-len(data_df.columns)+2)))\n",
    "    data_df = pd.concat([data_df,padding],axis=1)\n",
    "    \n",
    "    def padder (group):\n",
    "        padding=pd.DataFrame(np.append(np.ones((6-len(group), 1)) * group[\"PT_ID\"].values[0],\n",
    "                                       0*np.ones((6-len(group), len(data_df.columns) -1)),\n",
    "                                   axis=1),\n",
    "                             columns=data_df.columns)\n",
    "        return pd.concat([padding,group],axis=0)\n",
    "    \n",
    "    data_df = data_df.groupby(['PT_ID','Sepsis_Date']).apply(padder).reset_index(drop=True)    \n",
    "\n",
    "    \n",
    "    test_data=data_df\n",
    "    test_feature = test_data.drop([\"Label\",\"Sepsis_Date\"], axis=1)        \n",
    "    test_label = label_df[[\"Label\"]]\n",
    "    \n",
    "    scaler = joblib.load(\"trained_model/\"+d+\"_scaler_lstm.pkl\")\n",
    "    test_feature = scaler.transform(test_feature)        \n",
    "    test_feature=test_feature.reshape(-1, 6, 1742)        \n",
    "    \n",
    "    in_size= test_feature.shape[2]\n",
    "    h_size=256\n",
    "    \n",
    "    model = lstm(in_size=in_size,h_size=h_size)\n",
    "    model=model.cuda()\n",
    "    model.load_state_dict(torch.load(\"trained_model/\"+d+\"_lstm.pt\"))\n",
    "    \n",
    "    h = torch.zeros(1, len(test_feature), h_size, requires_grad=False)\n",
    "    c = torch.zeros(1, len(test_feature), h_size, requires_grad=False)\n",
    "    \n",
    "    y_pre=torch.round(model(torch.cuda.FloatTensor(test_feature),(h.cuda(),c.cuda()))).cpu().detach().numpy()\n",
    "    y_proba=model(torch.cuda.FloatTensor(test_feature),(h.cuda(),c.cuda())).cpu().detach().numpy()\n",
    "    y_label = test_label.values       \n",
    "    \n",
    "    test_acc  = (y_pre==y_label).sum()/len(y_label)\n",
    "    AUROC     = roc_auc_score(y_label, y_proba)\n",
    "    AUPRC     = average_precision_score(y_label, y_proba)\n",
    "    precision = precision_score(y_label, y_pre, pos_label=1)\n",
    "    recall    = recall_score(y_label, y_pre)\n",
    "    f1_score_ = f1_score(y_label, y_pre)\n",
    "    \n",
    "    print(\"ResNet10 : \")\n",
    "    print(\"  Acc      : \",np.round(test_acc ,3)) \n",
    "    print(\"  AUROC    : \",np.round(AUROC    ,3))\n",
    "    print(\"  AUPRC    : \",np.round(AUPRC    ,3))\n",
    "    print(\"  Precision: \",np.round(precision,3))\n",
    "    print(\"  Recall   : \",np.round(recall   ,3))\n",
    "    print(\"  F1-score : \",np.round(f1_score_,3))\n",
    "    print(\"\\n\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaist_hc",
   "language": "python",
   "name": "kaist_hc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
