{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EHRs : \n",
      "1 fold\n",
      "epoch0\tloss:0.773\tacc:0.5 \tval_loss:0.633\tv_acc:0.69\n",
      "epoch100\tloss:0.572\tacc:0.741 \tval_loss:0.615\tv_acc:0.679\n",
      "epoch200\tloss:0.45\tacc:0.815 \tval_loss:0.589\tv_acc:0.701\n",
      "epoch300\tloss:0.358\tacc:0.883 \tval_loss:0.587\tv_acc:0.716\n",
      "epoch400\tloss:0.321\tacc:0.904 \tval_loss:0.591\tv_acc:0.72\n",
      "2 fold\n",
      "epoch0\tloss:0.689\tacc:0.538 \tval_loss:0.699\tv_acc:0.391\n",
      "epoch100\tloss:0.551\tacc:0.744 \tval_loss:0.662\tv_acc:0.619\n",
      "epoch200\tloss:0.401\tacc:0.858 \tval_loss:0.657\tv_acc:0.669\n",
      "epoch300\tloss:0.299\tacc:0.916 \tval_loss:0.658\tv_acc:0.672\n",
      "epoch400\tloss:0.263\tacc:0.93 \tval_loss:0.658\tv_acc:0.692\n",
      "3 fold\n",
      "epoch0\tloss:0.707\tacc:0.496 \tval_loss:0.739\tv_acc:0.331\n",
      "epoch100\tloss:0.552\tacc:0.753 \tval_loss:0.647\tv_acc:0.62\n",
      "epoch200\tloss:0.412\tacc:0.843 \tval_loss:0.656\tv_acc:0.613\n",
      "epoch300\tloss:0.31\tacc:0.911 \tval_loss:0.688\tv_acc:0.631\n",
      "epoch400\tloss:0.272\tacc:0.933 \tval_loss:0.708\tv_acc:0.638\n",
      "4 fold\n",
      "epoch0\tloss:0.689\tacc:0.54 \tval_loss:0.699\tv_acc:0.556\n",
      "epoch100\tloss:0.537\tacc:0.753 \tval_loss:0.703\tv_acc:0.595\n",
      "epoch200\tloss:0.384\tacc:0.868 \tval_loss:0.724\tv_acc:0.585\n",
      "epoch300\tloss:0.278\tacc:0.935 \tval_loss:0.758\tv_acc:0.569\n",
      "epoch400\tloss:0.24\tacc:0.952 \tval_loss:0.777\tv_acc:0.572\n",
      "5 fold\n",
      "epoch0\tloss:0.708\tacc:0.5 \tval_loss:0.667\tv_acc:0.663\n",
      "epoch100\tloss:0.553\tacc:0.745 \tval_loss:0.647\tv_acc:0.611\n",
      "epoch200\tloss:0.409\tacc:0.855 \tval_loss:0.683\tv_acc:0.604\n",
      "epoch300\tloss:0.31\tacc:0.918 \tval_loss:0.741\tv_acc:0.594\n",
      "epoch400\tloss:0.275\tacc:0.941 \tval_loss:0.771\tv_acc:0.564\n",
      "\n",
      "\n",
      "ResNet10 : \n",
      "  Acc      :  0.638\n",
      "  AUROC    :  0.644\n",
      "  AUPRC    :  0.437\n",
      "  Precision:  0.465\n",
      "  Recall   :  0.501\n",
      "  F1-score :  0.466\n",
      "\n",
      "\n",
      "EHRs_DrugRel : \n",
      "1 fold\n",
      "epoch0\tloss:0.709\tacc:0.483 \tval_loss:0.737\tv_acc:0.325\n",
      "epoch100\tloss:0.542\tacc:0.774 \tval_loss:0.645\tv_acc:0.631\n",
      "epoch200\tloss:0.387\tacc:0.871 \tval_loss:0.652\tv_acc:0.619\n",
      "epoch300\tloss:0.286\tacc:0.925 \tval_loss:0.684\tv_acc:0.616\n",
      "epoch400\tloss:0.249\tacc:0.944 \tval_loss:0.703\tv_acc:0.623\n",
      "2 fold\n",
      "epoch0\tloss:0.698\tacc:0.496 \tval_loss:0.704\tv_acc:0.447\n",
      "epoch100\tloss:0.536\tacc:0.79 \tval_loss:0.645\tv_acc:0.639\n",
      "epoch200\tloss:0.372\tacc:0.881 \tval_loss:0.637\tv_acc:0.639\n",
      "epoch300\tloss:0.259\tacc:0.948 \tval_loss:0.651\tv_acc:0.636\n",
      "epoch400\tloss:0.221\tacc:0.961 \tval_loss:0.659\tv_acc:0.629\n",
      "3 fold\n",
      "epoch0\tloss:0.719\tacc:0.5 \tval_loss:0.788\tv_acc:0.324\n",
      "epoch100\tloss:0.555\tacc:0.787 \tval_loss:0.624\tv_acc:0.672\n",
      "epoch200\tloss:0.404\tacc:0.861 \tval_loss:0.633\tv_acc:0.676\n",
      "epoch300\tloss:0.307\tacc:0.915 \tval_loss:0.664\tv_acc:0.666\n",
      "epoch400\tloss:0.267\tacc:0.936 \tval_loss:0.68\tv_acc:0.662\n",
      "4 fold\n",
      "epoch0\tloss:0.869\tacc:0.5 \tval_loss:0.892\tv_acc:0.337\n",
      "epoch100\tloss:0.579\tacc:0.762 \tval_loss:0.695\tv_acc:0.569\n",
      "epoch200\tloss:0.452\tacc:0.836 \tval_loss:0.685\tv_acc:0.598\n",
      "epoch300\tloss:0.355\tacc:0.882 \tval_loss:0.683\tv_acc:0.618\n",
      "epoch400\tloss:0.313\tacc:0.913 \tval_loss:0.684\tv_acc:0.618\n",
      "5 fold\n",
      "epoch0\tloss:0.7\tacc:0.503 \tval_loss:0.68\tv_acc:0.647\n",
      "epoch100\tloss:0.536\tacc:0.79 \tval_loss:0.635\tv_acc:0.65\n",
      "epoch200\tloss:0.362\tacc:0.903 \tval_loss:0.643\tv_acc:0.627\n",
      "epoch300\tloss:0.253\tacc:0.948 \tval_loss:0.685\tv_acc:0.627\n",
      "epoch400\tloss:0.217\tacc:0.96 \tval_loss:0.709\tv_acc:0.617\n",
      "\n",
      "\n",
      "ResNet10 : \n",
      "  Acc      :  0.63\n",
      "  AUROC    :  0.693\n",
      "  AUPRC    :  0.499\n",
      "  Precision:  0.449\n",
      "  Recall   :  0.649\n",
      "  F1-score :  0.531\n",
      "\n",
      "\n",
      "EHRs_DrugRel_Lab : \n",
      "1 fold\n",
      "epoch0\tloss:0.718\tacc:0.5 \tval_loss:0.806\tv_acc:0.31\n",
      "epoch100\tloss:0.52\tacc:0.773 \tval_loss:0.663\tv_acc:0.604\n",
      "epoch200\tloss:0.349\tacc:0.889 \tval_loss:0.699\tv_acc:0.616\n",
      "epoch300\tloss:0.24\tacc:0.95 \tval_loss:0.771\tv_acc:0.612\n",
      "epoch400\tloss:0.202\tacc:0.968 \tval_loss:0.807\tv_acc:0.608\n",
      "2 fold\n",
      "epoch0\tloss:0.698\tacc:0.509 \tval_loss:0.678\tv_acc:0.672\n",
      "epoch100\tloss:0.529\tacc:0.764 \tval_loss:0.617\tv_acc:0.685\n",
      "epoch200\tloss:0.355\tacc:0.895 \tval_loss:0.6\tv_acc:0.685\n",
      "epoch300\tloss:0.247\tacc:0.949 \tval_loss:0.623\tv_acc:0.692\n",
      "epoch400\tloss:0.21\tacc:0.962 \tval_loss:0.638\tv_acc:0.695\n",
      "3 fold\n",
      "epoch0\tloss:0.707\tacc:0.5 \tval_loss:0.756\tv_acc:0.321\n",
      "epoch100\tloss:0.528\tacc:0.806 \tval_loss:0.628\tv_acc:0.662\n",
      "epoch200\tloss:0.355\tacc:0.901 \tval_loss:0.658\tv_acc:0.638\n",
      "epoch300\tloss:0.248\tacc:0.946 \tval_loss:0.7\tv_acc:0.645\n",
      "epoch400\tloss:0.212\tacc:0.957 \tval_loss:0.72\tv_acc:0.645\n",
      "4 fold\n",
      "epoch0\tloss:0.703\tacc:0.492 \tval_loss:0.674\tv_acc:0.66\n",
      "epoch100\tloss:0.509\tacc:0.798 \tval_loss:0.657\tv_acc:0.65\n",
      "epoch200\tloss:0.335\tacc:0.897 \tval_loss:0.644\tv_acc:0.644\n",
      "epoch300\tloss:0.231\tacc:0.95 \tval_loss:0.661\tv_acc:0.641\n",
      "epoch400\tloss:0.197\tacc:0.965 \tval_loss:0.94\tv_acc:0.641\n",
      "5 fold\n",
      "epoch0\tloss:0.692\tacc:0.542 \tval_loss:0.694\tv_acc:0.479\n",
      "epoch100\tloss:0.515\tacc:0.795 \tval_loss:0.611\tv_acc:0.67\n",
      "epoch200\tloss:0.33\tacc:0.917 \tval_loss:0.606\tv_acc:0.67\n",
      "epoch300\tloss:0.221\tacc:0.961 \tval_loss:0.633\tv_acc:0.667\n",
      "epoch400\tloss:0.187\tacc:0.975 \tval_loss:0.649\tv_acc:0.667\n",
      "\n",
      "\n",
      "ResNet10 : \n",
      "  Acc      :  0.65\n",
      "  AUROC    :  0.702\n",
      "  AUPRC    :  0.499\n",
      "  Precision:  0.472\n",
      "  Recall   :  0.653\n",
      "  F1-score :  0.546\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from utils.Dataset import Dataset\n",
    "from net.networks import ResNet10\n",
    "import random\n",
    "import torch.random\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_auc_score,average_precision_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed(123)\n",
    "np.random.seed(123)\n",
    "random.seed(123)\n",
    "\n",
    "EHRs_DrugRel_Lab = pd.read_csv(\"preprocessed_data(dummy)/EHRs_DrugRel_Lab.csv\")\n",
    "Lab_col=EHRs_DrugRel_Lab.columns[101:136]\n",
    "DrugRel_col=EHRs_DrugRel_Lab.columns[346:1741]\n",
    "EHRs_DrugRel=EHRs_DrugRel_Lab.drop(Lab_col.values,axis=1)\n",
    "EHRs=EHRs_DrugRel.drop(DrugRel_col,axis=1)\n",
    "\n",
    "tc=[[1,2],[3,4],[5,6],[7,8],[9,0]]\n",
    "data={\"EHRs\":EHRs,\"EHRs_DrugRel\":EHRs_DrugRel,\"EHRs_DrugRel_Lab\":EHRs_DrugRel_Lab}\n",
    "\n",
    "for d in data.keys():\n",
    "    data_df=data[d]\n",
    "    print(d,\": \")\n",
    "    data_df=data_df.drop([\"Sepsis_Date\"],axis=1)\n",
    "    \n",
    "    resnet10_acc = []\n",
    "    resnet10_roc = []\n",
    "    resnet10_prc = []\n",
    "    resnet10_pre = []\n",
    "    resnet10_rec = []\n",
    "    resnet10_f1  = []\n",
    "    \n",
    "    for tc_1, tc_2 in tc:\n",
    "        print(int(tc_1/2)+1,\"fold\")        \n",
    "        padding = pd.DataFrame(0*np.ones((len(data_df), 1764-len(data_df.columns)+1)))\n",
    "        data_df = pd.concat([data_df,padding],axis=1) \n",
    "        train_data=data_df.loc[(data_df[\"PT_ID\"]%10!=tc_1) & (data_df[\"PT_ID\"]%10!=tc_2)]\n",
    "        test_data=data_df.loc[(data_df[\"PT_ID\"]%10==tc_1) |(data_df[\"PT_ID\"]%10==tc_2)]\n",
    "        train_feature = train_data.drop([\"Label\"], axis=1)\n",
    "        train_label = train_data[[\"Label\"]]\n",
    "        test_feature = test_data.drop([\"Label\"], axis=1)\n",
    "        test_label = test_data[[\"Label\"]]        \n",
    "        scaler = MinMaxScaler()\n",
    "        train_feature = scaler.fit_transform(train_feature)\n",
    "        test_feature = scaler.transform(test_feature)        \n",
    "        rd = RandomUnderSampler()\n",
    "        train_feature, train_label = rd.fit_resample(train_feature,train_label)\n",
    "        train_feature=train_feature.reshape(train_feature.shape[0],1,42,42)\n",
    "        test_feature=test_feature.reshape(test_feature.shape[0],1,42,42)\n",
    "        \n",
    "        BATCH_SIZE=int(len(train_feature)/2)        \n",
    "        n_epochs=500\n",
    "        LEARNING_RATE=0.00001    \n",
    "        \n",
    "        train_data = Dataset(torch.FloatTensor(train_feature), torch.FloatTensor(train_label.values))\n",
    "        test_data = Dataset(torch.FloatTensor(test_feature), torch.FloatTensor(test_label.values))\n",
    "        train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        test_loader = DataLoader(dataset=test_data, batch_size=len(test_feature), shuffle=False)\n",
    "        \n",
    "        model=ResNet10()        \n",
    "        model=model.cuda()\n",
    "        loss_f = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs*len(train_loader), eta_min=0)\n",
    "\n",
    "        #forward loop\n",
    "        losses = []\n",
    "        accur = []\n",
    "        val_losses = []\n",
    "        val_accur = []        \n",
    "        \n",
    "        for i in range(n_epochs):\n",
    "            if i == 500:\n",
    "                break;\n",
    "            total_loss = 0\n",
    "            total_acc = 0 \n",
    "            val_total_loss = 0\n",
    "            val_total_acc = 0 \n",
    "            for j,(x_train,y_train) in enumerate(train_loader):\n",
    "                x_train,y_train=x_train.cuda(),y_train.cuda()                \n",
    "                output = model(x_train)\n",
    "                loss = loss_f(output,y_train.reshape(-1,1))        \n",
    "                acc = (torch.round(output.reshape(-1)) == y_train.reshape(-1)).sum()/len(y_train)\n",
    "        \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                total_loss+=loss.item()\n",
    "                total_acc+=acc.item()\n",
    "                \n",
    "            with torch.no_grad():    \n",
    "                for j,(x_test,y_test) in enumerate(test_loader):\n",
    "                    x_test,y_test=x_test.cuda(),y_test.cuda()\n",
    "                    y_pre = model(x_test)\n",
    "                    val_loss = loss_f(y_pre,y_test.reshape(-1,1))                    \n",
    "                    val_acc=(torch.round(y_pre.reshape(-1)) == y_test.reshape(-1)).sum()/len(y_test)\n",
    "                    val_total_loss+=val_loss.item()\n",
    "                    val_total_acc+=val_acc.item()\n",
    "                    \n",
    "            total_loss = total_loss/len(train_loader)\n",
    "            total_acc = total_acc/len(train_loader)\n",
    "            val_total_loss = val_total_loss/len(test_loader)\n",
    "            val_total_acc = val_total_acc/len(test_loader)\n",
    "            \n",
    "            if i%100 == 0:\n",
    "                losses.append(loss)\n",
    "                accur.append(acc)\n",
    "                val_losses.append(val_loss)\n",
    "                print(\"epoch{}\\tloss:{}\\tacc:{}\"\n",
    "                      .format(i,np.round(total_loss,3),np.round(total_acc,3)),\n",
    "                      \"\\tval_loss:{}\\tv_acc:{}\"\n",
    "                      .format(np.round(val_total_loss,3),np.round(val_total_acc,3)))\n",
    "\n",
    "        y_pre=torch.round(model(torch.cuda.FloatTensor(test_feature))).cpu().detach().numpy()\n",
    "        y_proba=model(torch.cuda.FloatTensor(test_feature)).cpu().detach().numpy()\n",
    "        \n",
    "        y_label = test_label.values\n",
    "        \n",
    "        test_acc  = (y_pre==y_label).sum()/len(y_label)\n",
    "        AUROC     = roc_auc_score(y_label, y_proba)\n",
    "        AUPRC     = average_precision_score(y_label, y_proba)\n",
    "        precision = precision_score(y_label, y_pre, pos_label=1)\n",
    "        recall    = recall_score(y_label, y_pre)\n",
    "        f1_score_ = f1_score(y_label, y_pre)\n",
    "        \n",
    "        resnet10_acc = resnet10_acc + [test_acc]\n",
    "        resnet10_roc = resnet10_roc + [AUROC]\n",
    "        resnet10_prc = resnet10_prc + [AUPRC]\n",
    "        resnet10_pre = resnet10_pre + [precision]\n",
    "        resnet10_rec = resnet10_rec + [recall]\n",
    "        resnet10_f1  = resnet10_f1  + [f1_score_]\n",
    "\n",
    "        #torch.save(model.state_dict(), \"trained_model/\"+d+\"_\"+str(tc_1)+\"_resnet10.pt\")\n",
    "        #joblib.dump(scaler, \"trained_model/\"+d+\"_\"+str(tc_1)+\"_scaler_resnet10.pkl\")        \n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"ResNet10 : \")\n",
    "    print(\"  Acc      : \",np.round(np.array(resnet10_acc).mean(),3))\n",
    "    print(\"  AUROC    : \",np.round(np.array(resnet10_roc).mean(),3))\n",
    "    print(\"  AUPRC    : \",np.round(np.array(resnet10_prc).mean(),3))\n",
    "    print(\"  Precision: \",np.round(np.array(resnet10_pre).mean(),3))\n",
    "    print(\"  Recall   : \",np.round(np.array(resnet10_rec).mean(),3))\n",
    "    print(\"  F1-score : \",np.round(np.array(resnet10_f1 ).mean(),3))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaist_hc",
   "language": "python",
   "name": "kaist_hc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
